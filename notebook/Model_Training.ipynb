{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "MfGOMpvdVSQp",
        "outputId": "5855d6f8-9a23-4299-b55d-635798232cb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.74-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.11)\n",
            "Collecting requests>=2.26\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->yfinance) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.26->yfinance) (1.24.3)\n",
            "Installing collected packages: requests, yfinance\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed requests-2.28.1 yfinance-0.1.74\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip3 install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tOdRkYid6IHl"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5C60yRDH6XRW"
      },
      "outputs": [],
      "source": [
        "def processData(coin):\n",
        "  #Reading data\n",
        "  BASE_URL = '../data/'\n",
        "  data = pd.read_csv(BASE_URL + coin + '.csv')\n",
        "\n",
        "  #Creating date\n",
        "  data['Date'] = pd.to_datetime(data['timestamp'], unit = 's').dt.date\n",
        "\n",
        "  #Intializing variable\n",
        "  dates = data['Date'].unique()\n",
        "  dates = list(dates)\n",
        "  for i in range(len(dates)):\n",
        "    dates[i] = str(dates[i])\n",
        "\n",
        "  #Extracting ['Date', 'Close'] and setting 'date' as index\n",
        "  data = data[['Close', 'Date']]\n",
        "  data['Date'] = data['Date'].astype(str)\n",
        "\n",
        "  final_data = []\n",
        "\n",
        "  #Creating day-wise dataframe for the given data\n",
        "  for i in dates:\n",
        "    max = data[data['Date'] == i][-1:]\n",
        "    final_data.append(max)\n",
        "\n",
        "  #Reshape data to 2D\n",
        "  final_data = np.array(final_data).reshape(len(final_data), 2)\n",
        "\n",
        "  #Converting to DataFrame\n",
        "  cols = data.columns\n",
        "  final_data = pd.DataFrame(final_data, columns = cols)\n",
        "\n",
        "  return final_data.set_index('Date', drop = True)\n",
        "\n",
        "def preprocessData(dataCleaned):\n",
        "  data_matrix = []\n",
        "  col = 10\n",
        "\n",
        "  # Normalizing data\n",
        "  scaler = MinMaxScaler()\n",
        "  dataCleaned['Close'] = dataCleaned['Close'].astype(float)\n",
        "  dataCleaned['Close'] = scaler.fit_transform(np.array(dataCleaned['Close']).reshape(-1,1))\n",
        "\n",
        "  for i in range(len(dataCleaned) - col+1):\n",
        "    data_matrix.append(dataCleaned[i:i+col].values)\n",
        "\n",
        "  row = int(len(data_matrix) * 0.7)\n",
        "  dataCleaned = np.asarray(data_matrix)\n",
        "\n",
        "  # # Splitting data\n",
        "  X_train, y_train = dataCleaned[:row, :-1], dataCleaned[:row, -1]\n",
        "  X_test, y_test = dataCleaned[row:, :-1], dataCleaned[row:, -1]\n",
        "\n",
        "  # Reshaping feature variables\n",
        "  # 1. X_train\n",
        "  shape = list(X_train.shape)\n",
        "  totShape = np.prod(shape)\n",
        "  main = int(totShape/9)\n",
        "\n",
        "  X_train = np.array(X_train).reshape(main, 1, 9)\n",
        "\n",
        "  # 2. X_test\n",
        "  shape = list(X_test.shape)\n",
        "  totShape = np.prod(shape)\n",
        "  main = int(totShape/9)\n",
        "\n",
        "  X_test = np.array(X_test).reshape(main, 1, 9)\n",
        "\n",
        "  return scaler, X_train, y_train, X_test, y_test\n",
        "\n",
        "def model_train(X_train, y_train, coin):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.LSTM(units = 30, input_shape = (None, 9), return_sequences = True))\n",
        "  model.add(tf.keras.layers.Dense(units = 32, activation = 'linear'))\n",
        "  model.add(tf.keras.layers.LSTM(units = 30, return_sequences = False))\n",
        "  model.add(tf.keras.layers.Dense(units = 1, activation = 'linear'))\n",
        "\n",
        "  model.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['mse'])\n",
        "\n",
        "  model.fit(X_train, y_train, batch_size = 5, epochs = 25, validation_split = .02)\n",
        "  \n",
        "  path = f'../models/{coin}.h5'\n",
        "  model.save(f'../models/{coin}.h5')\n",
        "  \n",
        "  return f'Model saved successfully at {path}!'\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "def predict_NextDay(scaler, coin):\n",
        "  MODEL_PATH = f'../models/{coin}.h5' \n",
        "  model = load_model(MODEL_PATH)\n",
        "  coins_dict = {\n",
        "    'dogecoin' : 'DOGE-USD',\n",
        "    'bitcoin' : 'BTC-USD',\n",
        "    'ethereum' : 'ETH-USD',\n",
        "    'iota' : 'MIOTA-USD',\n",
        "    'tron' : 'TRX-USD'\n",
        "  }\n",
        "\n",
        "  ticker = coins_dict[coin]\n",
        "\n",
        "  today = datetime.date.today()\n",
        "  d1 = today.strftime(\"%Y-%m-%d\")\n",
        "  d2 = datetime.date.today() - datetime.timedelta(days = 9)\n",
        "  d2 = d2.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "  new_sample = yf.download(ticker, start = d2, end = d1, progress = False)\n",
        "\n",
        "  last9 = new_sample[['Close']]\n",
        "  vals = last9.values\n",
        "\n",
        "  temp = []\n",
        "\n",
        "  for i in range(len(vals)):\n",
        "    temp.append(vals[0][0])\n",
        "\n",
        "  sample = scaler.fit_transform(np.array(temp).reshape(-1, 1))\n",
        "  sample = np.asarray(sample)[:-1]\n",
        "\n",
        "  sample = np.reshape(sample, (1, 1, 9))\n",
        "\n",
        "  prediction = model.predict(sample, batch_size = 2)\n",
        "\n",
        "  prediction = scaler.inverse_transform(prediction)\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "2npci8bLVpxF"
      },
      "outputs": [],
      "source": [
        "coins_dict = {\n",
        "    'dogecoin' : 'DOGE-USD',\n",
        "    'bitcoin' : 'BTC-USD',\n",
        "    'ethereum' : 'ETH-USD',\n",
        "    'iota' : 'MIOTA-USD',\n",
        "    'tron' : 'TRX-USD'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9v4EBSy2WqM3",
        "outputId": "32019f09-3490-4dd4-b4ad-aa96b8e81d88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'DOGE-USD'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coins_dict['dogecoin']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "22DPEaAv6__a"
      },
      "outputs": [],
      "source": [
        "data = processData('dogecoin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LOT8y38_-ALl"
      },
      "outputs": [],
      "source": [
        "scaler, X_train, y_train, X_test, y_test = preprocessData(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8IDEtD4JDzQn",
        "outputId": "c9d625e5-e651-4fe8-9254-641bb86de92e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "122/122 [==============================] - 3s 6ms/step - loss: 8.6577e-07 - mse: 8.6577e-07 - val_loss: 6.9689e-06 - val_mse: 6.9689e-06\n",
            "Epoch 2/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.2034e-07 - mse: 5.2034e-07 - val_loss: 2.8727e-06 - val_mse: 2.8727e-06\n",
            "Epoch 3/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 6.9385e-07 - mse: 6.9385e-07 - val_loss: 1.2450e-05 - val_mse: 1.2450e-05\n",
            "Epoch 4/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 8.0624e-07 - mse: 8.0624e-07 - val_loss: 3.8912e-06 - val_mse: 3.8912e-06\n",
            "Epoch 5/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 6.3938e-07 - mse: 6.3938e-07 - val_loss: 3.0363e-06 - val_mse: 3.0363e-06\n",
            "Epoch 6/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 6.8020e-07 - mse: 6.8020e-07 - val_loss: 4.0604e-06 - val_mse: 4.0604e-06\n",
            "Epoch 7/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.8600e-07 - mse: 5.8600e-07 - val_loss: 4.3994e-06 - val_mse: 4.3994e-06\n",
            "Epoch 8/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.8020e-07 - mse: 4.8020e-07 - val_loss: 5.7302e-06 - val_mse: 5.7302e-06\n",
            "Epoch 9/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.8969e-07 - mse: 5.8969e-07 - val_loss: 6.3985e-06 - val_mse: 6.3985e-06\n",
            "Epoch 10/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.4926e-07 - mse: 5.4926e-07 - val_loss: 2.6532e-06 - val_mse: 2.6532e-06\n",
            "Epoch 11/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.1781e-07 - mse: 5.1781e-07 - val_loss: 3.2002e-06 - val_mse: 3.2002e-06\n",
            "Epoch 12/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.7842e-07 - mse: 4.7842e-07 - val_loss: 4.7661e-06 - val_mse: 4.7661e-06\n",
            "Epoch 13/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.4897e-07 - mse: 4.4897e-07 - val_loss: 3.2326e-06 - val_mse: 3.2326e-06\n",
            "Epoch 14/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.3025e-07 - mse: 4.3025e-07 - val_loss: 2.6961e-06 - val_mse: 2.6961e-06\n",
            "Epoch 15/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.1406e-07 - mse: 5.1406e-07 - val_loss: 3.6952e-06 - val_mse: 3.6952e-06\n",
            "Epoch 16/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.8596e-07 - mse: 4.8596e-07 - val_loss: 6.0478e-06 - val_mse: 6.0478e-06\n",
            "Epoch 17/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.3877e-07 - mse: 5.3877e-07 - val_loss: 5.6659e-06 - val_mse: 5.6659e-06\n",
            "Epoch 18/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.5858e-07 - mse: 5.5858e-07 - val_loss: 7.1534e-06 - val_mse: 7.1534e-06\n",
            "Epoch 19/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.0634e-07 - mse: 4.0634e-07 - val_loss: 1.1504e-06 - val_mse: 1.1504e-06\n",
            "Epoch 20/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 5.6718e-07 - mse: 5.6718e-07 - val_loss: 3.5966e-06 - val_mse: 3.5966e-06\n",
            "Epoch 21/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 4.0288e-07 - mse: 4.0288e-07 - val_loss: 4.6799e-06 - val_mse: 4.6799e-06\n",
            "Epoch 22/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 3.3316e-07 - mse: 3.3316e-07 - val_loss: 2.8676e-06 - val_mse: 2.8676e-06\n",
            "Epoch 23/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 2.4927e-07 - mse: 2.4927e-07 - val_loss: 1.9552e-06 - val_mse: 1.9552e-06\n",
            "Epoch 24/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 2.3782e-07 - mse: 2.3782e-07 - val_loss: 1.5628e-06 - val_mse: 1.5628e-06\n",
            "Epoch 25/25\n",
            "122/122 [==============================] - 0s 2ms/step - loss: 1.7705e-07 - mse: 1.7705e-07 - val_loss: 1.7336e-06 - val_mse: 1.7336e-06\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Model saved successfully at ../models/dogecoin.h5!'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_train(X_train, y_train, 'dogecoin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68I94AWrUKui",
        "outputId": "14997437-3bc2-4dc3-9225-159c37a27391"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.08195435]], dtype=float32)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_NextDay(scaler, 'dogecoin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD2h-iFleUy7",
        "outputId": "c69d20e3-8462-40b1-d2d3-196de390dc44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "186/186 [==============================] - 3s 5ms/step - loss: 6.1786e-04 - mse: 6.1786e-04 - val_loss: 1.6950e-04 - val_mse: 1.6950e-04\n",
            "Epoch 2/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 9.6080e-05 - mse: 9.6080e-05 - val_loss: 1.7928e-04 - val_mse: 1.7928e-04\n",
            "Epoch 3/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 7.2270e-05 - mse: 7.2270e-05 - val_loss: 1.4900e-04 - val_mse: 1.4900e-04\n",
            "Epoch 4/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 6.4957e-05 - mse: 6.4957e-05 - val_loss: 5.6752e-05 - val_mse: 5.6752e-05\n",
            "Epoch 5/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.4341e-05 - mse: 5.4341e-05 - val_loss: 1.4751e-04 - val_mse: 1.4751e-04\n",
            "Epoch 6/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.1496e-05 - mse: 5.1496e-05 - val_loss: 4.0726e-05 - val_mse: 4.0726e-05\n",
            "Epoch 7/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.3424e-05 - mse: 5.3424e-05 - val_loss: 3.8590e-05 - val_mse: 3.8590e-05\n",
            "Epoch 8/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.8717e-05 - mse: 4.8717e-05 - val_loss: 3.8839e-05 - val_mse: 3.8839e-05\n",
            "Epoch 9/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.5786e-05 - mse: 4.5786e-05 - val_loss: 4.3220e-05 - val_mse: 4.3220e-05\n",
            "Epoch 10/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.3356e-05 - mse: 5.3356e-05 - val_loss: 4.1701e-05 - val_mse: 4.1701e-05\n",
            "Epoch 11/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.2711e-05 - mse: 4.2711e-05 - val_loss: 7.4086e-05 - val_mse: 7.4086e-05\n",
            "Epoch 12/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.3841e-05 - mse: 4.3841e-05 - val_loss: 3.4290e-05 - val_mse: 3.4290e-05\n",
            "Epoch 13/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.4409e-05 - mse: 4.4409e-05 - val_loss: 3.5100e-05 - val_mse: 3.5100e-05\n",
            "Epoch 14/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.3394e-05 - mse: 4.3394e-05 - val_loss: 3.5323e-05 - val_mse: 3.5323e-05\n",
            "Epoch 15/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.1363e-05 - mse: 5.1363e-05 - val_loss: 3.5372e-05 - val_mse: 3.5372e-05\n",
            "Epoch 16/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.0373e-05 - mse: 5.0373e-05 - val_loss: 3.1641e-04 - val_mse: 3.1641e-04\n",
            "Epoch 17/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.8458e-05 - mse: 4.8458e-05 - val_loss: 8.5559e-05 - val_mse: 8.5559e-05\n",
            "Epoch 18/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.1624e-05 - mse: 4.1624e-05 - val_loss: 3.4070e-05 - val_mse: 3.4070e-05\n",
            "Epoch 19/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.5808e-05 - mse: 4.5808e-05 - val_loss: 5.1269e-05 - val_mse: 5.1269e-05\n",
            "Epoch 20/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.2462e-05 - mse: 4.2462e-05 - val_loss: 1.2122e-04 - val_mse: 1.2122e-04\n",
            "Epoch 21/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.5713e-05 - mse: 4.5713e-05 - val_loss: 9.5902e-05 - val_mse: 9.5902e-05\n",
            "Epoch 22/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.5520e-05 - mse: 4.5520e-05 - val_loss: 3.7110e-05 - val_mse: 3.7110e-05\n",
            "Epoch 23/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.3513e-05 - mse: 4.3513e-05 - val_loss: 8.8853e-05 - val_mse: 8.8853e-05\n",
            "Epoch 24/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.1837e-05 - mse: 4.1837e-05 - val_loss: 3.5958e-05 - val_mse: 3.5958e-05\n",
            "Epoch 25/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.1353e-05 - mse: 4.1353e-05 - val_loss: 6.2892e-05 - val_mse: 6.2892e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[24319.334]], dtype=float32)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Bitcoin\n",
        "coin = 'bitcoin'\n",
        "data = processData(coin)\n",
        "scaler, X_train, y_train, X_test, y_test = preprocessData(data)\n",
        "model_train(X_train, y_train, coin)\n",
        "predict_NextDay(scaler, coin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw_7HVDZe2Oa",
        "outputId": "331ea198-e5a4-4742-bc51-09bec236ddac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "186/186 [==============================] - 3s 5ms/step - loss: 8.9399e-04 - mse: 8.9399e-04 - val_loss: 1.6973e-04 - val_mse: 1.6973e-04\n",
            "Epoch 2/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 1.2470e-04 - mse: 1.2470e-04 - val_loss: 9.6381e-05 - val_mse: 9.6381e-05\n",
            "Epoch 3/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 1.1299e-04 - mse: 1.1299e-04 - val_loss: 4.9017e-05 - val_mse: 4.9017e-05\n",
            "Epoch 4/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 8.6345e-05 - mse: 8.6345e-05 - val_loss: 1.4774e-04 - val_mse: 1.4774e-04\n",
            "Epoch 5/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 8.4322e-05 - mse: 8.4322e-05 - val_loss: 1.1027e-04 - val_mse: 1.1027e-04\n",
            "Epoch 6/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 8.8567e-05 - mse: 8.8567e-05 - val_loss: 8.1287e-05 - val_mse: 8.1287e-05\n",
            "Epoch 7/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 7.3394e-05 - mse: 7.3394e-05 - val_loss: 3.5143e-05 - val_mse: 3.5143e-05\n",
            "Epoch 8/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 7.0598e-05 - mse: 7.0598e-05 - val_loss: 1.7855e-05 - val_mse: 1.7855e-05\n",
            "Epoch 9/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 6.6090e-05 - mse: 6.6090e-05 - val_loss: 2.3041e-05 - val_mse: 2.3041e-05\n",
            "Epoch 10/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 7.0346e-05 - mse: 7.0346e-05 - val_loss: 3.5946e-05 - val_mse: 3.5946e-05\n",
            "Epoch 11/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.5735e-05 - mse: 5.5735e-05 - val_loss: 6.2833e-05 - val_mse: 6.2833e-05\n",
            "Epoch 12/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.6029e-05 - mse: 5.6029e-05 - val_loss: 2.1771e-05 - val_mse: 2.1771e-05\n",
            "Epoch 13/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.0806e-05 - mse: 5.0806e-05 - val_loss: 1.5329e-05 - val_mse: 1.5329e-05\n",
            "Epoch 14/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.7732e-05 - mse: 5.7732e-05 - val_loss: 3.7784e-05 - val_mse: 3.7784e-05\n",
            "Epoch 15/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.9405e-05 - mse: 5.9405e-05 - val_loss: 2.6238e-05 - val_mse: 2.6238e-05\n",
            "Epoch 16/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.9131e-05 - mse: 5.9131e-05 - val_loss: 2.8724e-05 - val_mse: 2.8724e-05\n",
            "Epoch 17/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.4586e-05 - mse: 5.4586e-05 - val_loss: 2.5641e-05 - val_mse: 2.5641e-05\n",
            "Epoch 18/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.0304e-05 - mse: 5.0304e-05 - val_loss: 2.8584e-05 - val_mse: 2.8584e-05\n",
            "Epoch 19/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.9387e-05 - mse: 4.9387e-05 - val_loss: 1.5056e-05 - val_mse: 1.5056e-05\n",
            "Epoch 20/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.0074e-05 - mse: 5.0074e-05 - val_loss: 4.8624e-05 - val_mse: 4.8624e-05\n",
            "Epoch 21/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.9566e-05 - mse: 5.9566e-05 - val_loss: 1.5558e-05 - val_mse: 1.5558e-05\n",
            "Epoch 22/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 6.7906e-05 - mse: 6.7906e-05 - val_loss: 1.4707e-05 - val_mse: 1.4707e-05\n",
            "Epoch 23/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 4.8792e-05 - mse: 4.8792e-05 - val_loss: 4.6684e-05 - val_mse: 4.6684e-05\n",
            "Epoch 24/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.5016e-05 - mse: 5.5016e-05 - val_loss: 1.3452e-05 - val_mse: 1.3452e-05\n",
            "Epoch 25/25\n",
            "186/186 [==============================] - 0s 2ms/step - loss: 5.1013e-05 - mse: 5.1013e-05 - val_loss: 1.3583e-05 - val_mse: 1.3583e-05\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1936.8021]], dtype=float32)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Ethereum\n",
        "coin = 'ethereum'\n",
        "data = processData(coin)\n",
        "scaler, X_train, y_train, X_test, y_test = preprocessData(data)\n",
        "model_train(X_train, y_train, coin)\n",
        "predict_NextDay(scaler, coin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8rrXva8gNTY",
        "outputId": "6ab9fa50-1bc9-4ac3-9b26-3882ff84ec32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "168/168 [==============================] - 3s 6ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.8486e-04 - val_mse: 3.8486e-04\n",
            "Epoch 2/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 7.0046e-04 - mse: 7.0046e-04 - val_loss: 3.7623e-04 - val_mse: 3.7623e-04\n",
            "Epoch 3/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 6.2609e-04 - mse: 6.2609e-04 - val_loss: 1.2399e-04 - val_mse: 1.2399e-04\n",
            "Epoch 4/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 5.4909e-04 - mse: 5.4909e-04 - val_loss: 1.1536e-04 - val_mse: 1.1536e-04\n",
            "Epoch 5/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 5.1902e-04 - mse: 5.1902e-04 - val_loss: 8.2237e-05 - val_mse: 8.2237e-05\n",
            "Epoch 6/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 4.8879e-04 - mse: 4.8879e-04 - val_loss: 8.6221e-05 - val_mse: 8.6221e-05\n",
            "Epoch 7/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 4.8091e-04 - mse: 4.8091e-04 - val_loss: 1.1789e-04 - val_mse: 1.1789e-04\n",
            "Epoch 8/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.6556e-04 - mse: 3.6556e-04 - val_loss: 9.2190e-05 - val_mse: 9.2190e-05\n",
            "Epoch 9/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.4850e-04 - mse: 3.4850e-04 - val_loss: 1.5098e-04 - val_mse: 1.5098e-04\n",
            "Epoch 10/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.6090e-04 - mse: 3.6090e-04 - val_loss: 1.3149e-04 - val_mse: 1.3149e-04\n",
            "Epoch 11/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.9270e-04 - mse: 2.9270e-04 - val_loss: 9.6525e-05 - val_mse: 9.6525e-05\n",
            "Epoch 12/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.3114e-04 - mse: 3.3114e-04 - val_loss: 1.3404e-04 - val_mse: 1.3404e-04\n",
            "Epoch 13/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.1103e-04 - mse: 3.1103e-04 - val_loss: 1.0400e-04 - val_mse: 1.0400e-04\n",
            "Epoch 14/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.0704e-04 - mse: 3.0704e-04 - val_loss: 2.9134e-04 - val_mse: 2.9134e-04\n",
            "Epoch 15/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.9945e-04 - mse: 2.9945e-04 - val_loss: 1.4277e-04 - val_mse: 1.4277e-04\n",
            "Epoch 16/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.3975e-04 - mse: 3.3975e-04 - val_loss: 7.3498e-05 - val_mse: 7.3498e-05\n",
            "Epoch 17/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.5766e-04 - mse: 3.5766e-04 - val_loss: 8.5713e-05 - val_mse: 8.5713e-05\n",
            "Epoch 18/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.6170e-04 - mse: 2.6170e-04 - val_loss: 7.3333e-05 - val_mse: 7.3333e-05\n",
            "Epoch 19/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.5823e-04 - mse: 2.5823e-04 - val_loss: 2.0359e-04 - val_mse: 2.0359e-04\n",
            "Epoch 20/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.1296e-04 - mse: 3.1296e-04 - val_loss: 7.9091e-05 - val_mse: 7.9091e-05\n",
            "Epoch 21/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.3267e-04 - mse: 2.3267e-04 - val_loss: 6.1935e-05 - val_mse: 6.1935e-05\n",
            "Epoch 22/25\n",
            "168/168 [==============================] - 0s 3ms/step - loss: 2.7528e-04 - mse: 2.7528e-04 - val_loss: 1.0354e-04 - val_mse: 1.0354e-04\n",
            "Epoch 23/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.8040e-04 - mse: 2.8040e-04 - val_loss: 8.3126e-05 - val_mse: 8.3126e-05\n",
            "Epoch 24/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 2.4016e-04 - mse: 2.4016e-04 - val_loss: 2.4616e-04 - val_mse: 2.4616e-04\n",
            "Epoch 25/25\n",
            "168/168 [==============================] - 0s 2ms/step - loss: 3.0237e-04 - mse: 3.0237e-04 - val_loss: 1.0827e-04 - val_mse: 1.0827e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.35421285]], dtype=float32)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#IOTA\n",
        "coin = 'iota'\n",
        "data = processData(coin)\n",
        "scaler, X_train, y_train, X_test, y_test = preprocessData(data)\n",
        "model_train(X_train, y_train, coin)\n",
        "predict_NextDay(scaler, coin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mebGKMN6gVLW",
        "outputId": "7e65e83d-6986-4a2a-8d40-4acd494be45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "181/181 [==============================] - 3s 5ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 5.8136e-04 - val_mse: 5.8136e-04\n",
            "Epoch 2/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 5.5091e-04 - mse: 5.5091e-04 - val_loss: 6.4725e-04 - val_mse: 6.4725e-04\n",
            "Epoch 3/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 4.3056e-04 - mse: 4.3056e-04 - val_loss: 1.9550e-04 - val_mse: 1.9550e-04\n",
            "Epoch 4/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 4.1160e-04 - mse: 4.1160e-04 - val_loss: 1.7619e-04 - val_mse: 1.7619e-04\n",
            "Epoch 5/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.7299e-04 - mse: 2.7299e-04 - val_loss: 8.4099e-04 - val_mse: 8.4099e-04\n",
            "Epoch 6/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.4025e-04 - mse: 2.4025e-04 - val_loss: 2.0195e-04 - val_mse: 2.0195e-04\n",
            "Epoch 7/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.5381e-04 - mse: 2.5381e-04 - val_loss: 2.0552e-04 - val_mse: 2.0552e-04\n",
            "Epoch 8/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.5586e-04 - mse: 2.5586e-04 - val_loss: 2.0907e-04 - val_mse: 2.0907e-04\n",
            "Epoch 9/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.6515e-04 - mse: 2.6515e-04 - val_loss: 1.6714e-04 - val_mse: 1.6714e-04\n",
            "Epoch 10/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.1106e-04 - mse: 2.1106e-04 - val_loss: 1.9898e-04 - val_mse: 1.9898e-04\n",
            "Epoch 11/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.1995e-04 - mse: 2.1995e-04 - val_loss: 1.8110e-04 - val_mse: 1.8110e-04\n",
            "Epoch 12/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.4723e-04 - mse: 2.4723e-04 - val_loss: 1.4486e-04 - val_mse: 1.4486e-04\n",
            "Epoch 13/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.1059e-04 - mse: 2.1059e-04 - val_loss: 1.4878e-04 - val_mse: 1.4878e-04\n",
            "Epoch 14/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.4549e-04 - mse: 2.4549e-04 - val_loss: 2.1249e-04 - val_mse: 2.1249e-04\n",
            "Epoch 15/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.3350e-04 - mse: 2.3350e-04 - val_loss: 1.4585e-04 - val_mse: 1.4585e-04\n",
            "Epoch 16/25\n",
            "181/181 [==============================] - 0s 3ms/step - loss: 2.0072e-04 - mse: 2.0072e-04 - val_loss: 1.4078e-04 - val_mse: 1.4078e-04\n",
            "Epoch 17/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.4204e-04 - mse: 2.4204e-04 - val_loss: 1.5624e-04 - val_mse: 1.5624e-04\n",
            "Epoch 18/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.5702e-04 - mse: 2.5702e-04 - val_loss: 2.0812e-04 - val_mse: 2.0812e-04\n",
            "Epoch 19/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.1480e-04 - mse: 2.1480e-04 - val_loss: 1.7139e-04 - val_mse: 1.7139e-04\n",
            "Epoch 20/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.0461e-04 - mse: 2.0461e-04 - val_loss: 1.3936e-04 - val_mse: 1.3936e-04\n",
            "Epoch 21/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.3461e-04 - mse: 2.3461e-04 - val_loss: 1.9068e-04 - val_mse: 1.9068e-04\n",
            "Epoch 22/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 1.9702e-04 - mse: 1.9702e-04 - val_loss: 1.4992e-04 - val_mse: 1.4992e-04\n",
            "Epoch 23/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 2.2847e-04 - mse: 2.2847e-04 - val_loss: 1.5534e-04 - val_mse: 1.5534e-04\n",
            "Epoch 24/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 1.9204e-04 - mse: 1.9204e-04 - val_loss: 1.6240e-04 - val_mse: 1.6240e-04\n",
            "Epoch 25/25\n",
            "181/181 [==============================] - 0s 2ms/step - loss: 1.9696e-04 - mse: 1.9696e-04 - val_loss: 1.3093e-04 - val_mse: 1.3093e-04\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015A32A79820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000015A32A79820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.07986443]], dtype=float32)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TRON\n",
        "coin = 'tron'\n",
        "data = processData(coin)\n",
        "scaler, X_train, y_train, X_test, y_test = preprocessData(data)\n",
        "model_train(X_train, y_train, coin)\n",
        "predict_NextDay(scaler, coin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksnfPAtLgZR-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Model-Training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "c081257499a92776a7ff5343ee4d85420a7950a6ae97b0cb2aee7a7ddd41b7f2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
